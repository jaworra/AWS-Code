AWSTemplateFormatVersion: '2010-09-09'
Description: Builld S3 and inline lambdas
Resources:
  S3Bucket:
    Type: AWS::S3::Bucket
    Properties: 
      BucketName: cloudformation-build-incidentsdashboard-jaworra

  lambdaFunction:
    Type: AWS::Lambda::Function
    Properties:
      Description: Python Function Handler
      FunctionName: test_jaworra_cloudformation_build
      Handler: index.handler
      MemorySize: 128
      Role: arn:aws:iam::708280501988:role/lambda_generic
      Runtime: python2.7 
      Code:
        ZipFile: |
          #Feature extraction from available API
          #todo: 1) refactor holiday and next 24 hour result
          #      2) set cloud watch  

          # Based on location of incident ('In progres') return proximity HERE flow network
          # Save S3 location
          bucketname_routes="public-test-road"
          filepath_incidents_read_prefix_key="stat/"
          filepath_incidents_statistic_write = "public-test-road/stat/"

          # Athena parametres
          DATABASE = 'incidents'
          TABLE = 'daily_summaries_dashboard'
          S3_OUTPUT = 's3://public-test-road/stat/qry'
          S3_BUCKET = 'qry'
          RETRY_COUNT = 5 # number of retries

          #------------------ queries run on below athena table-----------------------
          #create table if required below athena db *refrence incase tabld is dropped
          '''
          CREATE EXTERNAL TABLE IF NOT EXISTS historic_incidents_db.daily_summaries_partition(
          `date` string,
          `weekday` string,
          'incidentcount` int,
          `crashcount` int 
          ) PARTITIONED BY (
          `yymmdd_utcplus10` string 
          )
          ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe'
          WITH SERDEPROPERTIES (
            'serialization.format' = ',',
            'field.delim' = ','
          ) LOCATION 's3://public-test-road/stat/bytime/'
          TBLPROPERTIES ('has_encrypted_data'='false')
          '''

          import boto3
          import json
          import datetime
          from datetime import date, timedelta
          from botocore.vendored import requests
          import urllib2
          import json

          from athena_lambda import *
          
          def athena_next_24_hrs_past_24_hrs():
            '''
            create a rolling 48hour window for dashboard statistics every 24hours (set at 1145)
            
            '''
            #set current date 
            dt=datetime.datetime.utcnow() + datetime.timedelta(hours=10)
            today = datetime.datetime.strftime(dt,"%Y%m%d") #string yyyymmdd
            day_of_week = dt.strftime('%A')
            
            #set tomorrows date 
            dt_24hours=dt + datetime.timedelta(hours=24) #24 hour previous 
            tomorrows_day_of_week = dt_24hours.strftime('%A')
            
            sel_stat_1 = 1
            sel_stat_2 = 2
            col_wkday = 'weekday'    
            col_inc = 'incidentcount' 
            col_hm = 'hhmm_utcplus10' 
            
            #anthena query
            '''
            SELECT weekday, hhmm_utcplus10, 1 as select_order,
            min (incidentcount) as "minimum_incidents",
            approx_percentile(incidentcount, 0.25) as "appx_Q1_incidents",
            AVG (incidentcount) as "average_incidents",
            approx_percentile(incidentcount, 0.75) as "appx_Q3_incidents",                      
            max (incidentcount) as "maximum_incidents"
            FROM "incidents"."daily_summaries_dashboard" where weekday = 'Monday' 
            GROUP BY weekday,hhmm_utcplus10
            UNION 
            SELECT weekday, hhmm_utcplus10, 2 as select_order,
            min (incidentcount) as "minimum_incidents",
            approx_percentile(incidentcount, 0.25) as "appx_Q1_incidents",
            AVG (incidentcount) as "average_incidents",
            approx_percentile(incidentcount, 0.75) as "appx_Q3_incidents",                      
            max (incidentcount) as "maximum_incidents"
            FROM "incidents"."daily_summaries_dashboard" where weekday = 'Tuesday' 
            GROUP BY weekday,hhmm_utcplus10 Order by select_order,hhmm_utcplus10
            '''
            
            query = "SELECT %s,%s,%d as select_order, " \
                "min (%s) as minimum_incidents," \
                "approx_percentile(%s, 0.25) as appx_Q1_incidents," \
                "AVG (%s) as average_incidents," \
                "approx_percentile(%s, 0.75) as appx_Q3_incidents," \
                "max (%s) as maximum_incidents " \
                "FROM %s.%s where %s = '%s' " \
                "GROUP BY %s,%s" \
                " UNION " \
                "SELECT %s,%s,%d as select_order, " \
                "min (%s) as minimum_incidents," \
                "approx_percentile(%s, 0.25) as appx_Q1_incidents," \
                "AVG (%s) as average_incidents," \
                "approx_percentile(%s, 0.75) as appx_Q3_incidents," \
                "max (%s) as maximum_incidents " \
                "FROM %s.%s where %s = '%s' " \
                "GROUP BY %s,%s ORDER BY select_order,%s;"  \
                % (col_wkday, col_hm,sel_stat_1,col_inc,col_inc,col_inc,col_inc,col_inc,
                DATABASE, TABLE, col_wkday, day_of_week,col_wkday,col_hm,
                col_wkday, col_hm,sel_stat_2,col_inc,col_inc,col_inc,col_inc,col_inc,
                DATABASE, TABLE, col_wkday, day_of_week,col_wkday,col_hm,col_hm) 
            
            #calls athena query
            results,query_execution_id = athena_qry(query,DATABASE,S3_OUTPUT,RETRY_COUNT)
        
            #using id move csv file to S3 curated bucket for typical weekday and weekend
            client_s3 = boto3.resource('s3')
            # Copy anthena query to curated csv for frontend rendering - html,D3
            client_s3.Object(bucketname_routes,  "stat/rolling_48_hour_window.csv").copy_from(CopySource= filepath_incidents_statistic_write + "qry/"+ query_execution_id + ".csv")
            
            # Delete the former object A
            client_s3.Object(bucketname_routes, "stat/qry/"+ query_execution_id + ".csv").delete()
            client_s3.Object(bucketname_routes, "stat/qry/"+ query_execution_id + ".csv.metadata").delete()
            #set lifecycle policy in bucket subfolder - month exipiry (28-32 files)
            print 'SUCCESSFUL - athena_next_24_hrs_past_24_hrs'  
            return
